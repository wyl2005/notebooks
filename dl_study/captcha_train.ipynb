{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "FLAGS=tf.app.flags.FLAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.app.flags.DEFINE_string(\"captcha_dir\", \"./data/captcha/captcha.tfrecords\", \"验证码数据路径\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.app.flags.DEFINE_integer(\"batch_size\",100,\"每批次训练的样本数\")\n",
    "tf.app.flags.DEFINE_integer(\"label_num\", 4,\"每个样本的目标值数量\")\n",
    "tf.app.flags.DEFINE_integer(\"letter_num\", 26,\"每个目标值的字母的可能性个数\")\n",
    "tf.app.flags.DEFINE_string(\"f\", \"\",\"fix bug\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_and_decode():\n",
    "    \"\"\"\n",
    "    读取验证码数据API\n",
    "    return: image_batch=[100,20,80,3], label_batch=[100, 4]\n",
    "    \"\"\"\n",
    "    # 1. 构建文件队列\n",
    "    file_queue = tf.train.string_input_producer([FLAGS.captcha_dir])\n",
    "    \n",
    "    # 2. 构建文件阅读器、读取文件内容，默认读取一个样本\n",
    "    reader = tf.TFRecordReader()\n",
    "    \n",
    "    # 3. 读取内容,key: filename,\n",
    "    key, value = reader.read(file_queue)\n",
    "    \n",
    "    # 4. parse tfrecords example\n",
    "    features = tf.parse_single_example(value, features={\n",
    "        \"image\":tf.FixedLenFeature([], tf.string),\n",
    "        \"label\":tf.FixedLenFeature([], tf.string)\n",
    "    })\n",
    "    \n",
    "    # 解码内容，字符串内容\n",
    "    # 解析图片的特征值\n",
    "    image = tf.decode_raw(features[\"image\"], tf.uint8)\n",
    "\n",
    "    # 解析图片的目标值\n",
    "    label = tf.decode_raw(features[\"label\"], tf.uint8)\n",
    "    \n",
    "    print(image, label)\n",
    "    # 改变形状\n",
    "    image_reshape = tf.reshape(image, [20, 80, 3])\n",
    "    label_reshape = tf.reshape(label, [4])\n",
    "    \n",
    "    print(image_reshape, label_reshape)\n",
    "    \n",
    "    # 批处理，每次读取的样本数 100， 即每次训练的时候的样本\n",
    "    image_batch, label_batch = tf.train.batch([image_reshape, label_reshape],\n",
    "                                             batch_size=FLAGS.batch_size,\n",
    "                                             num_threads=1,\n",
    "                                             capacity=FLAGS.batch_size) \n",
    "    \n",
    "    print(image_batch,label_batch)\n",
    "    return image_batch, label_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fc_model(image):\n",
    "    \"\"\"\n",
    "    image: 100 images, features [100, 20, 80, 3]\n",
    "    return: y_predict [100, 4*26]\n",
    "    \"\"\"\n",
    "    with tf.variable_scope(\"model\"):\n",
    "        # 1. input reshape\n",
    "        image_reshape = tf.reshape(image, [-1, 20*80*3])\n",
    "        \n",
    "        # 2. init weights [20*80*3, 4*26] bias=[4*26]\n",
    "        # matrix[100, 20 * 80 * 3] * [20 * 80 * 3, 4 * 26] + [104] = [100, 4 * 26]\n",
    "        weights = tf.Variable(tf.random_normal([20*80*3, 4*26], mean=0.0, stddev=1.0))\n",
    "        bias = tf.Variable(tf.constant(0.0,shape=[4*26]))\n",
    "        \n",
    "        # 3. full connect layer calcuate \n",
    "        y_predict = tf.matmul(tf.cast(image_reshape, tf.float32), weights) + bias\n",
    "    return y_predict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n            将读取文件当中的目标值转换成one_hot编码\\n            label:[100, 4] [[13,25,15,15],[19,23,20,16]......]\\n            return: [100, 4, 26]\\n            '"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# def predict_to_onehot(label):\n",
    "    \"\"\"\n",
    "    将读取文件当中的目标值转换成one_hot编码\n",
    "    label:[100, 4] [[13,25,15,15],[19,23,20,16]......]\n",
    "    return: [100, 4, 26]\n",
    "    \"\"\"\n",
    "    # 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0213 04:19:03.191406 140087226820416 deprecation.py:323] From <ipython-input-5-739332c3d1a7>:7: string_input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(string_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n",
      "W0213 04:19:03.297010 140087226820416 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/input.py:278: input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(input_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n",
      "W0213 04:19:03.303275 140087226820416 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/input.py:190: limit_epochs (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensors(tensor).repeat(num_epochs)`.\n",
      "W0213 04:19:03.318029 140087226820416 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/input.py:199: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "W0213 04:19:03.332691 140087226820416 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/input.py:199: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "W0213 04:19:03.355364 140087226820416 deprecation.py:323] From <ipython-input-5-739332c3d1a7>:10: TFRecordReader.__init__ (from tensorflow.python.ops.io_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.TFRecordDataset`.\n",
      "W0213 04:19:03.393032 140087226820416 deprecation.py:323] From <ipython-input-5-739332c3d1a7>:39: batch (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.batch(batch_size)` (or `padded_batch(...)` if `dynamic_pad=True`).\n",
      "W0213 04:19:03.498710 140087226820416 deprecation.py:323] From <ipython-input-8-9f84b7b67ec9>:24: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"DecodeRaw:0\", shape=(?,), dtype=uint8) Tensor(\"DecodeRaw_1:0\", shape=(?,), dtype=uint8)\n",
      "Tensor(\"Reshape:0\", shape=(20, 80, 3), dtype=uint8) Tensor(\"Reshape_1:0\", shape=(4,), dtype=uint8)\n",
      "Tensor(\"batch:0\", shape=(100, 20, 80, 3), dtype=uint8) Tensor(\"batch:1\", shape=(100, 4), dtype=uint8)\n",
      "y_predict: Tensor(\"model/add:0\", shape=(100, 104), dtype=float32)\n",
      "y_true: Tensor(\"one_hot:0\", shape=(100, 4, 26), dtype=float32)\n",
      "Tensor(\"soft_cross/Mean:0\", shape=(), dtype=float32)\n",
      "Tensor(\"optimizer_1/Equal:0\", shape=(100, 4), dtype=bool)\n",
      "Tensor(\"optimizer_1/Mean:0\", shape=(100,), dtype=int8)\n",
      "Tensor(\"optimizer_1/Mean_1:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# def captcha_rec():\n",
    "\n",
    "# 1. 读取验证码的数据文件  image_batch=[100,20,80,3], label_batch=[100, 4] \n",
    "image_batch, label_batch = read_and_decode()\n",
    "# print(image_batch, label_batch)\n",
    "\n",
    "# 2. 通过输入图片特征, 建立模型，得出预测结果\n",
    "# 一层 全连接神经网络进行预测\n",
    "# matric [100, 20*80*3] * [20*80*3, 4*26] + [4*26] = [100, 4*26]\n",
    "y_predict = fc_model(image_batch)\n",
    "print(\"y_predict:\",y_predict)\n",
    "\n",
    "# 3. 把真实的目标值转换成one-hot编码 \n",
    "# label_batch:[100, 4] [[13,25,15,15],[19,23,20,16]......] \n",
    "# [100, 4] -> [100, 4, 26]\n",
    "y_true = tf.one_hot(label_batch, depth=26, on_value=1.0, axis=2)\n",
    "print(\"y_true:\", y_true)\n",
    "\n",
    "# 4. softmax计算，交叉熵损失计算 二维计算损失\n",
    "with tf.variable_scope(\"soft_cross\"):\n",
    "    # 求平均交叉熵损失\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "        labels=tf.reshape(y_true,[100,4*26]),\n",
    "        logits=y_predict))\n",
    "    print(loss)\n",
    "\n",
    "# 5. 梯度下降优化损失\n",
    "with tf.variable_scope(\"optimizer\"):\n",
    "    train_op = tf.train.GradientDescentOptimizer(0.01).minimize(loss)\n",
    "    \n",
    "# 6. 求出样本每批次的准确率是多少， 三维比较 \n",
    "with tf.variable_scope(\"optimizer\"):\n",
    "    # 比较每个预测值和目标值是否位置（4个位置）一样\n",
    "    # y_true [100, 4, 26]  y_predict [100, 4*26] -> [100, 4, 26]\n",
    "    # equal_list_2d [100, 4] \n",
    "    equal_list_2d = tf.equal(\n",
    "        tf.argmax(y_true,axis=2),\n",
    "        tf.argmax(tf.reshape(y_predict,[100,4,26]),axis=2)\n",
    "    )\n",
    "    print(equal_list_2d)\n",
    "    \n",
    "    # equal_list:[100,4] -> reduce_mean(axis=1) -> [100] -> reduce_mean() -> scalar \n",
    "    result_list_1d = tf.reduce_mean(\n",
    "        tf.cast(equal_list_2d, tf.int8),\n",
    "        axis=1\n",
    "    )\n",
    "    print(result_list_1d)\n",
    "    \n",
    "    accuracy = tf.reduce_mean(tf.cast(result_list_1d, tf.float32))\n",
    "    print(accuracy)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0213 04:19:03.769759 140087226820416 deprecation.py:323] From <ipython-input-9-e0c006ab9ddc>:21: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 batchs accuracy=0.000000\n",
      "100 batchs accuracy=0.000000\n",
      "200 batchs accuracy=0.040000\n",
      "300 batchs accuracy=0.200000\n",
      "400 batchs accuracy=0.480000\n",
      "500 batchs accuracy=0.560000\n",
      "600 batchs accuracy=0.720000\n",
      "700 batchs accuracy=0.830000\n",
      "800 batchs accuracy=0.880000\n",
      "900 batchs accuracy=0.850000\n",
      "1000 batchs accuracy=0.820000\n",
      "1100 batchs accuracy=0.920000\n",
      "1200 batchs accuracy=0.900000\n",
      "1300 batchs accuracy=0.900000\n",
      "1400 batchs accuracy=0.890000\n",
      "1500 batchs accuracy=0.800000\n",
      "1600 batchs accuracy=0.900000\n",
      "1700 batchs accuracy=0.960000\n",
      "1800 batchs accuracy=0.950000\n",
      "1900 batchs accuracy=0.900000\n",
      "2000 batchs accuracy=0.900000\n",
      "2100 batchs accuracy=0.940000\n",
      "2200 batchs accuracy=0.950000\n",
      "2300 batchs accuracy=0.920000\n",
      "2400 batchs accuracy=0.950000\n",
      "2500 batchs accuracy=0.970000\n",
      "2600 batchs accuracy=0.850000\n",
      "2700 batchs accuracy=0.970000\n",
      "2800 batchs accuracy=0.870000\n",
      "2900 batchs accuracy=0.890000\n",
      "3000 batchs accuracy=0.950000\n",
      "3100 batchs accuracy=0.900000\n",
      "3200 batchs accuracy=0.960000\n",
      "3300 batchs accuracy=0.970000\n",
      "3400 batchs accuracy=0.900000\n",
      "3500 batchs accuracy=0.980000\n",
      "3600 batchs accuracy=0.960000\n",
      "3700 batchs accuracy=0.910000\n",
      "3800 batchs accuracy=0.880000\n",
      "3900 batchs accuracy=0.970000\n",
      "4000 batchs accuracy=0.940000\n",
      "4100 batchs accuracy=0.980000\n",
      "4200 batchs accuracy=0.990000\n",
      "4300 batchs accuracy=0.980000\n",
      "4400 batchs accuracy=0.950000\n",
      "4500 batchs accuracy=0.940000\n",
      "4600 batchs accuracy=0.960000\n",
      "4700 batchs accuracy=0.980000\n",
      "4800 batchs accuracy=0.910000\n",
      "4900 batchs accuracy=0.960000\n"
     ]
    }
   ],
   "source": [
    "# 定义一个初始化变量的op\n",
    "init_op = tf.global_variables_initializer()\n",
    "\n",
    "# 定义一个保存模型的实例\n",
    "saver = tf.train.Saver(max_to_keep=5)\n",
    "\n",
    "# 开启会话训练\n",
    "with tf.Session() as sess:\n",
    "    # 初始化变量\n",
    "    sess.run(init_op)\n",
    "    \n",
    "    # 加载模型\n",
    "    if os.path.exists(\"./ckpt/captcha/captcha_model.data-00000-of-00001\"):\n",
    "        saver.restore(sess, \"./ckpt/captcha/captcha_model\")\n",
    "        print(\"restore!!!\")\n",
    "    \n",
    "    # 定义线程协调器和开启线程\n",
    "    coord = tf.train.Coordinator()\n",
    "    \n",
    "    # 开启线程去运行读取文件操作\n",
    "    threads = tf.train.start_queue_runners(sess, coord=coord)\n",
    "    \n",
    "#     print(sess.run(y_true))\n",
    "#     print(sess.run(equal_list_2d))\n",
    "#     print(sess.run(result_list_1d))\n",
    "    # 循环训练\n",
    "    for i in range(5000):\n",
    "        sess.run(train_op)\n",
    "#         print(\"%d batchs accuracy=%f\" % (i, sess.run(accuracy)))\n",
    "        \n",
    "        if i%100 == 0:\n",
    "            saver.save(sess, \"./ckpt/captcha/captcha_model\")\n",
    "            print(\"%d batchs accuracy=%f\" % (i, sess.run(accuracy)))\n",
    "    \n",
    "    # 回收线程\n",
    "    coord.request_stop()\n",
    "    coord.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.exists(\"./ckpt/captcha/captcha_model.data-00000-of-00001\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method save in module tensorflow.python.training.saver:\n",
      "\n",
      "save(sess, save_path, global_step=None, latest_filename=None, meta_graph_suffix='meta', write_meta_graph=True, write_state=True, strip_default_attrs=False, save_debug_info=False) method of tensorflow.python.training.saver.Saver instance\n",
      "    Saves variables.\n",
      "    \n",
      "    This method runs the ops added by the constructor for saving variables.\n",
      "    It requires a session in which the graph was launched.  The variables to\n",
      "    save must also have been initialized.\n",
      "    \n",
      "    The method returns the path prefix of the newly created checkpoint files.\n",
      "    This string can be passed directly to a call to `restore()`.\n",
      "    \n",
      "    Args:\n",
      "      sess: A Session to use to save the variables.\n",
      "      save_path: String.  Prefix of filenames created for the checkpoint.\n",
      "      global_step: If provided the global step number is appended to `save_path`\n",
      "        to create the checkpoint filenames. The optional argument can be a\n",
      "        `Tensor`, a `Tensor` name or an integer.\n",
      "      latest_filename: Optional name for the protocol buffer file that will\n",
      "        contains the list of most recent checkpoints.  That file, kept in the\n",
      "        same directory as the checkpoint files, is automatically managed by the\n",
      "        saver to keep track of recent checkpoints.  Defaults to 'checkpoint'.\n",
      "      meta_graph_suffix: Suffix for `MetaGraphDef` file. Defaults to 'meta'.\n",
      "      write_meta_graph: `Boolean` indicating whether or not to write the meta\n",
      "        graph file.\n",
      "      write_state: `Boolean` indicating whether or not to write the\n",
      "        `CheckpointStateProto`.\n",
      "      strip_default_attrs: Boolean. If `True`, default-valued attributes will be\n",
      "        removed from the NodeDefs. For a detailed guide, see\n",
      "        [Stripping Default-Valued\n",
      "          Attributes](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/saved_model/README.md#stripping-default-valued-attributes).\n",
      "      save_debug_info: If `True`, save the GraphDebugInfo to a separate file,\n",
      "        which in the same directory of save_path and with `_debug` added before\n",
      "        the file extension. This is only enabled when `write_meta_graph` is\n",
      "        `True`\n",
      "    \n",
      "    Returns:\n",
      "      A string: path prefix used for the checkpoint files.  If the saver is\n",
      "        sharded, this string ends with: '-?????-of-nnnnn' where 'nnnnn'\n",
      "        is the number of shards created.\n",
      "      If the saver is empty, returns None.\n",
      "    \n",
      "    Raises:\n",
      "      TypeError: If `sess` is not a `Session`.\n",
      "      ValueError: If `latest_filename` contains path components, or if it\n",
      "        collides with `save_path`.\n",
      "      RuntimeError: If save and restore ops weren't built.\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-8fa4f06c8d8f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mthreads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_queue_runners\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoord\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcoord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"label\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'features' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "with tf.Session() as sess:\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(sess, coord=coord)\n",
    "    \n",
    "    print(sess.run(features[\"label\"]))\n",
    "    print(sess.run(label))\n",
    "    \n",
    "    coord.request_stop()\n",
    "    coord.join(threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = b'\\r\\x19\\x0f\\x0f'\n",
    "b = b'\\r\\n'\n",
    "for i in b:\n",
    "    \n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
