{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"ReaderReadV2_11:0\", shape=(), dtype=string)\n",
      "Tensor(\"ReaderReadV2_11:1\", shape=(), dtype=string)\n",
      "Tensor(\"DecodeCSV_11:0\", shape=(), dtype=string)\n",
      "Tensor(\"DecodeCSV_11:2\", shape=(), dtype=int32)\n",
      "[b'Sea2', 8]\n",
      "[b'./data/csv_data/B.csv:3', b'Bee3,B3,6']\n",
      "[array([b'Sea1', b'Sea3', b'Bee1'], dtype=object)]\n",
      "[array([b'B2', b'A1', b'A2'], dtype=object)]\n",
      "[array([3, 7, 8], dtype=int32)]\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"./data/csv_data\"\n",
    "filelist = [os.path.join(data_dir, i) for i in os.listdir(data_dir)]\n",
    "filelist\n",
    "\n",
    "file_queue = tf.train.string_input_producer(filelist, shuffle=False)\n",
    "\n",
    "reader = tf.TextLineReader()\n",
    "\n",
    "key, value = reader.read(file_queue)\n",
    "\n",
    "print(key)\n",
    "print(value)\n",
    "\n",
    "# 3. decode\n",
    "records = [[\"None\"],[\"None\"], [3]]\n",
    "a, b, c = tf.decode_csv(value, record_defaults=records)\n",
    "\n",
    "a_batch , b_batch, c_batch= tf.train.batch([a,b, c],\n",
    "                                  batch_size=3,\n",
    "                                  num_threads =1,\n",
    "                                  capacity=3)\n",
    "\n",
    "print(a)\n",
    "print(c)\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    # 开启读取文件的线程\n",
    "    coord=tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(sess, coord=coord)\n",
    "    \n",
    "    print(sess.run([a, c]))\n",
    "    print(sess.run([key, value]))\n",
    "    \n",
    "    print(sess.run([a_batch]))\n",
    "    print(sess.run([b_batch]))\n",
    "    print(sess.run([c_batch]))\n",
    "    # 回收子线程\n",
    "    coord.request_stop()\n",
    "    coord.join(threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function batch in module tensorflow.python.training.input:\n",
      "\n",
      "batch(tensors, batch_size, num_threads=1, capacity=32, enqueue_many=False, shapes=None, dynamic_pad=False, allow_smaller_final_batch=False, shared_name=None, name=None)\n",
      "    Creates batches of tensors in `tensors`. (deprecated)\n",
      "    \n",
      "    Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      "    Instructions for updating:\n",
      "    Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.batch(batch_size)` (or `padded_batch(...)` if `dynamic_pad=True`).\n",
      "    \n",
      "    The argument `tensors` can be a list or a dictionary of tensors.\n",
      "    The value returned by the function will be of the same type\n",
      "    as `tensors`.\n",
      "    \n",
      "    This function is implemented using a queue. A `QueueRunner` for the\n",
      "    queue is added to the current `Graph`'s `QUEUE_RUNNER` collection.\n",
      "    \n",
      "    If `enqueue_many` is `False`, `tensors` is assumed to represent a single\n",
      "    example.  An input tensor with shape `[x, y, z]` will be output as a tensor\n",
      "    with shape `[batch_size, x, y, z]`.\n",
      "    \n",
      "    If `enqueue_many` is `True`, `tensors` is assumed to represent a batch of\n",
      "    examples, where the first dimension is indexed by example, and all members of\n",
      "    `tensors` should have the same size in the first dimension.  If an input\n",
      "    tensor has shape `[*, x, y, z]`, the output will have shape `[batch_size, x,\n",
      "    y, z]`.  The `capacity` argument controls the how long the prefetching is\n",
      "    allowed to grow the queues.\n",
      "    \n",
      "    The returned operation is a dequeue operation and will throw\n",
      "    `tf.errors.OutOfRangeError` if the input queue is exhausted. If this\n",
      "    operation is feeding another input queue, its queue runner will catch\n",
      "    this exception, however, if this operation is used in your main thread\n",
      "    you are responsible for catching this yourself.\n",
      "    \n",
      "    *N.B.:* If `dynamic_pad` is `False`, you must ensure that either\n",
      "    (i) the `shapes` argument is passed, or (ii) all of the tensors in\n",
      "    `tensors` must have fully-defined shapes. `ValueError` will be\n",
      "    raised if neither of these conditions holds.\n",
      "    \n",
      "    If `dynamic_pad` is `True`, it is sufficient that the *rank* of the\n",
      "    tensors is known, but individual dimensions may have shape `None`.\n",
      "    In this case, for each enqueue the dimensions with value `None`\n",
      "    may have a variable length; upon dequeue, the output tensors will be padded\n",
      "    on the right to the maximum shape of the tensors in the current minibatch.\n",
      "    For numbers, this padding takes value 0.  For strings, this padding is\n",
      "    the empty string.  See `PaddingFIFOQueue` for more info.\n",
      "    \n",
      "    If `allow_smaller_final_batch` is `True`, a smaller batch value than\n",
      "    `batch_size` is returned when the queue is closed and there are not enough\n",
      "    elements to fill the batch, otherwise the pending elements are discarded.\n",
      "    In addition, all output tensors' static shapes, as accessed via the\n",
      "    `shape` property will have a first `Dimension` value of `None`, and\n",
      "    operations that depend on fixed batch_size would fail.\n",
      "    \n",
      "    Args:\n",
      "      tensors: The list or dictionary of tensors to enqueue.\n",
      "      batch_size: The new batch size pulled from the queue.\n",
      "      num_threads: The number of threads enqueuing `tensors`.  The batching will\n",
      "        be nondeterministic if `num_threads > 1`.\n",
      "      capacity: An integer. The maximum number of elements in the queue.\n",
      "      enqueue_many: Whether each tensor in `tensors` is a single example.\n",
      "      shapes: (Optional) The shapes for each example.  Defaults to the\n",
      "        inferred shapes for `tensors`.\n",
      "      dynamic_pad: Boolean.  Allow variable dimensions in input shapes.\n",
      "        The given dimensions are padded upon dequeue so that tensors within a\n",
      "        batch have the same shapes.\n",
      "      allow_smaller_final_batch: (Optional) Boolean. If `True`, allow the final\n",
      "        batch to be smaller if there are insufficient items left in the queue.\n",
      "      shared_name: (Optional). If set, this queue will be shared under the given\n",
      "        name across multiple sessions.\n",
      "      name: (Optional) A name for the operations.\n",
      "    \n",
      "    Returns:\n",
      "      A list or dictionary of tensors with the same types as `tensors` (except if\n",
      "      the input is a list of one element, then it returns a tensor, not a list).\n",
      "    \n",
      "    Raises:\n",
      "      ValueError: If the `shapes` are not specified, and cannot be\n",
      "        inferred from the elements of `tensors`.\n",
      "    \n",
      "    @compatibility(eager)\n",
      "    Input pipelines based on Queues are not supported when eager execution is\n",
      "    enabled. Please use the `tf.data` API to ingest data under eager execution.\n",
      "    @end_compatibility\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tf.train.batch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
