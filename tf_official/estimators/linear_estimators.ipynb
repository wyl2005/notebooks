{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.feature_column as fc\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (2.22.0)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /usr/lib/python3/dist-packages (from requests) (2.6)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests) (1.25.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests) (2019.6.16)\n",
      "\u001b[33mWARNING: You are using pip version 19.1.1, however version 19.2.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_path = os.path.join(os.getcwd(), 'models')\n",
    "sys.path.append(models_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0725 08:33:50.089238 140427323885376 deprecation_wrapper.py:119] From /tf/notebooks/tf_official/estimators/models/official/wide_deep/census_dataset.py:78: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
      "\n",
      "W0725 08:33:50.090740 140427323885376 deprecation_wrapper.py:119] From /tf/notebooks/tf_official/estimators/models/official/wide_deep/census_dataset.py:81: The name tf.gfile.Exists is deprecated. Please use tf.io.gfile.exists instead.\n",
      "\n",
      "W0725 08:37:24.219202 140427323885376 deprecation_wrapper.py:119] From /tf/notebooks/tf_official/estimators/models/official/wide_deep/census_dataset.py:62: The name tf.gfile.Open is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n",
      "W0725 08:37:24.549461 140427323885376 deprecation_wrapper.py:119] From /tf/notebooks/tf_official/estimators/models/official/wide_deep/census_dataset.py:73: The name tf.gfile.Remove is deprecated. Please use tf.io.gfile.remove instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from official.wide_deep import census_dataset\n",
    "from official.wide_deep import census_main\n",
    "\n",
    "census_dataset.download(\"/tmp/census_data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"PYTHONPATH\" in os.environ:\n",
    "  os.environ['PYTHONPATH'] += os.pathsep +  models_path\n",
    "else:\n",
    "  os.environ['PYTHONPATH'] = models_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\r\n",
      "W0725 08:40:17.243052 140126278432576 deprecation_wrapper.py:119] From /tf/notebooks/tf_official/estimators/models/official/wide_deep/census_main.py:114: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\r\n",
      "\r\n",
      "W0725 08:40:17.243367 140126278432576 deprecation_wrapper.py:119] From /tf/notebooks/tf_official/estimators/models/official/wide_deep/census_main.py:114: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\r\n",
      "\r\n",
      "Train DNN on census income dataset.\r\n",
      "flags:\r\n",
      "\r\n",
      "/tf/notebooks/tf_official/estimators/models/official/wide_deep/census_main.py:\r\n",
      "  -bs,--batch_size:\r\n",
      "    Batch size for training and evaluation. When using multiple gpus, this is\r\n",
      "    the\r\n",
      "    global batch size for all devices. For example, if the batch size is 32 and\r\n",
      "    there are 4 GPUs, each GPU will get 8 examples on each step.\r\n",
      "    (default: '40')\r\n",
      "    (an integer)\r\n",
      "  --[no]clean:\r\n",
      "    If set, model_dir will be removed if it exists.\r\n",
      "    (default: 'false')\r\n",
      "  -dd,--data_dir:\r\n",
      "    The location of the input data.\r\n",
      "    (default: '/tmp/census_data')\r\n",
      "  --[no]download_if_missing:\r\n",
      "    Download data to data_dir if it is not already present.\r\n",
      "    (default: 'true')\r\n",
      "  -ebe,--epochs_between_evals:\r\n",
      "    The number of training epochs to run between evaluations.\r\n",
      "    (default: '2')\r\n",
      "    (an integer)\r\n",
      "  -ed,--export_dir:\r\n",
      "    If set, a SavedModel serialization of the model will be exported to this\r\n",
      "    directory at the end of training. See the README for more details and\r\n",
      "    relevant\r\n",
      "    links.\r\n",
      "  -hk,--hooks:\r\n",
      "    A list of (case insensitive) strings to specify the names of training hooks.\r\n",
      "    ﻿  Hook:\r\n",
      "    ﻿    loggingtensorhook\r\n",
      "    ﻿    profilerhook\r\n",
      "    ﻿    examplespersecondhook\r\n",
      "    ﻿    loggingmetrichook\r\n",
      "    ﻿    stepcounterhook\r\n",
      "    ﻿  Example: `--hooks ProfilerHook,ExamplesPerSecondHook`\r\n",
      "    See official.utils.logs.hooks_helper for details.\r\n",
      "    (default: 'LoggingTensorHook')\r\n",
      "    (a comma separated list)\r\n",
      "  -md,--model_dir:\r\n",
      "    The location of the model checkpoint files.\r\n",
      "    (default: '/tmp/census_model')\r\n",
      "  -mt,--model_type: <wide|deep|wide_deep>: Select model topology.\r\n",
      "    (default: 'wide_deep')\r\n",
      "  -te,--train_epochs:\r\n",
      "    The number of epochs used to train.\r\n",
      "    (default: '40')\r\n",
      "    (an integer)\r\n",
      "\r\n",
      "Try --helpfull to get a list of all flags.\r\n"
     ]
    }
   ],
   "source": [
    "!python -m official.wide_deep.census_main --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0725 08:41:23.016214 140510523660096 deprecation_wrapper.py:119] From /tf/notebooks/tf_official/estimators/models/official/wide_deep/census_main.py:114: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
      "\n",
      "W0725 08:41:23.016488 140510523660096 deprecation_wrapper.py:119] From /tf/notebooks/tf_official/estimators/models/official/wide_deep/census_main.py:114: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
      "\n",
      "W0725 08:41:23.020954 140510523660096 deprecation_wrapper.py:119] From /tf/notebooks/tf_official/estimators/models/official/wide_deep/census_dataset.py:78: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
      "\n",
      "W0725 08:41:23.021172 140510523660096 deprecation_wrapper.py:119] From /tf/notebooks/tf_official/estimators/models/official/wide_deep/census_dataset.py:81: The name tf.gfile.Exists is deprecated. Please use tf.io.gfile.exists instead.\n",
      "\n",
      "W0725 08:41:23.022311 140510523660096 deprecation_wrapper.py:119] From /tf/notebooks/tf_official/estimators/models/official/wide_deep/census_main.py:49: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "I0725 08:41:23.023130 140510523660096 estimator.py:209] Using config: {'_model_dir': '/tmp/census_model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': device_count {\n",
      "  key: \"GPU\"\n",
      "  value: 0\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fcabda5f400>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "W0725 08:41:23.071599 140510523660096 logger.py:387] 'cpuinfo' not imported. CPU info will not be logged.\n",
      "W0725 08:41:23.071931 140510523660096 logger.py:400] 'psutil' not imported. Memory info will not be logged.\n",
      "I0725 08:41:23.096234 140510523660096 logger.py:152] Benchmark run: {'model_name': 'wide_deep', 'dataset': {'name': 'Census Income'}, 'machine_config': {}, 'test_id': None, 'run_date': '2019-07-25T08:41:23.071048Z', 'tensorflow_version': {'version': '1.14.0', 'git_hash': 'v1.14.0-rc1-22-gaf24dc91b5'}, 'tensorflow_environment_variables': [], 'run_parameters': [{'name': 'batch_size', 'long_value': 40}, {'name': 'model_type', 'string_value': 'wide'}, {'name': 'train_epochs', 'long_value': 2}]}\n",
      "W0725 08:41:23.120195 140510523660096 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "W0725 08:41:23.159464 140510523660096 deprecation_wrapper.py:119] From /tf/notebooks/tf_official/estimators/models/official/wide_deep/census_dataset.py:167: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
      "\n",
      "I0725 08:41:23.159650 140510523660096 census_dataset.py:167] Parsing /tmp/census_data/adult.data\n",
      "W0725 08:41:23.159767 140510523660096 deprecation_wrapper.py:119] From /tf/notebooks/tf_official/estimators/models/official/wide_deep/census_dataset.py:168: The name tf.decode_csv is deprecated. Please use tf.io.decode_csv instead.\n",
      "\n",
      "I0725 08:41:23.209120 140510523660096 estimator.py:1145] Calling model_fn.\n",
      "W0725 08:41:23.691880 140510523660096 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/sparse_ops.py:1719: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0725 08:41:24.232718 140510523660096 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/canned/linear.py:308: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "I0725 08:41:25.054118 140510523660096 estimator.py:1147] Done calling model_fn.\n",
      "I0725 08:41:25.054480 140510523660096 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\n",
      "I0725 08:41:25.541802 140510523660096 monitored_session.py:240] Graph was finalized.\n",
      "2019-07-25 08:41:25.542184: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2019-07-25 08:41:25.552548: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Could not dlopen library 'libcuda.so.1'; dlerror: /usr/lib/x86_64-linux-gnu/libcuda.so.1: file too short; LD_LIBRARY_PATH: /usr/local/cuda/extras/CUPTI/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2019-07-25 08:41:25.552614: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2019-07-25 08:41:25.552683: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (6e2e109c4825): /proc/driver/nvidia/version does not exist\n",
      "2019-07-25 08:41:25.575299: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2097590000 Hz\n",
      "2019-07-25 08:41:25.576948: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x544f010 executing computations on platform Host. Devices:\n",
      "2019-07-25 08:41:25.576991: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\n",
      "2019-07-25 08:41:25.678841: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\n",
      "I0725 08:41:25.740614 140510523660096 session_manager.py:500] Running local_init_op.\n",
      "I0725 08:41:25.772284 140510523660096 session_manager.py:502] Done running local_init_op.\n",
      "I0725 08:41:26.894181 140510523660096 basic_session_run_hooks.py:606] Saving checkpoints for 0 into /tmp/census_model/model.ckpt.\n",
      "I0725 08:41:27.855525 140510523660096 basic_session_run_hooks.py:262] average_loss = 0.6931472, loss = 27.725887\n",
      "I0725 08:41:27.856057 140510523660096 basic_session_run_hooks.py:262] loss = 27.725887, step = 1\n",
      "I0725 08:41:28.552210 140510523660096 basic_session_run_hooks.py:692] global_step/sec: 143.402\n",
      "I0725 08:41:28.553108 140510523660096 basic_session_run_hooks.py:260] average_loss = 0.45842615, loss = 18.337046 (0.698 sec)\n",
      "I0725 08:41:28.553448 140510523660096 basic_session_run_hooks.py:260] loss = 18.337046, step = 101 (0.697 sec)\n",
      "I0725 08:41:28.859081 140510523660096 basic_session_run_hooks.py:692] global_step/sec: 325.826\n",
      "I0725 08:41:28.859798 140510523660096 basic_session_run_hooks.py:260] average_loss = 0.50601506, loss = 20.240602 (0.307 sec)\n",
      "I0725 08:41:28.860061 140510523660096 basic_session_run_hooks.py:260] loss = 20.240602, step = 201 (0.307 sec)\n",
      "I0725 08:41:29.167308 140510523660096 basic_session_run_hooks.py:692] global_step/sec: 324.451\n",
      "I0725 08:41:29.168118 140510523660096 basic_session_run_hooks.py:260] average_loss = 0.2426225, loss = 9.7049 (0.308 sec)\n",
      "I0725 08:41:29.168382 140510523660096 basic_session_run_hooks.py:260] loss = 9.7049, step = 301 (0.308 sec)\n",
      "I0725 08:41:29.480325 140510523660096 basic_session_run_hooks.py:692] global_step/sec: 319.449\n",
      "I0725 08:41:29.481015 140510523660096 basic_session_run_hooks.py:260] average_loss = 0.3893656, loss = 15.574625 (0.313 sec)\n",
      "I0725 08:41:29.481329 140510523660096 basic_session_run_hooks.py:260] loss = 15.574625, step = 401 (0.313 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0725 08:41:29.788779 140510523660096 basic_session_run_hooks.py:692] global_step/sec: 324.217\n",
      "I0725 08:41:29.789570 140510523660096 basic_session_run_hooks.py:260] average_loss = 0.32871822, loss = 13.148728 (0.309 sec)\n",
      "I0725 08:41:29.789878 140510523660096 basic_session_run_hooks.py:260] loss = 13.148728, step = 501 (0.309 sec)\n",
      "I0725 08:41:30.106144 140510523660096 basic_session_run_hooks.py:692] global_step/sec: 315.099\n",
      "I0725 08:41:30.106930 140510523660096 basic_session_run_hooks.py:260] average_loss = 0.33019137, loss = 13.207655 (0.317 sec)\n",
      "I0725 08:41:30.107261 140510523660096 basic_session_run_hooks.py:260] loss = 13.207655, step = 601 (0.317 sec)\n",
      "I0725 08:41:30.416978 140510523660096 basic_session_run_hooks.py:692] global_step/sec: 321.708\n",
      "I0725 08:41:30.417694 140510523660096 basic_session_run_hooks.py:260] average_loss = 0.40893573, loss = 16.35743 (0.311 sec)\n",
      "I0725 08:41:30.417929 140510523660096 basic_session_run_hooks.py:260] loss = 16.35743, step = 701 (0.311 sec)\n",
      "I0725 08:41:30.725143 140510523660096 basic_session_run_hooks.py:692] global_step/sec: 324.502\n",
      "I0725 08:41:30.725870 140510523660096 basic_session_run_hooks.py:260] average_loss = 0.57771385, loss = 23.108555 (0.308 sec)\n",
      "I0725 08:41:30.726203 140510523660096 basic_session_run_hooks.py:260] loss = 23.108555, step = 801 (0.308 sec)\n",
      "I0725 08:41:31.107649 140510523660096 basic_session_run_hooks.py:692] global_step/sec: 261.465\n",
      "I0725 08:41:31.108532 140510523660096 basic_session_run_hooks.py:260] average_loss = 0.34071207, loss = 13.628483 (0.383 sec)\n",
      "I0725 08:41:31.108901 140510523660096 basic_session_run_hooks.py:260] loss = 13.628483, step = 901 (0.383 sec)\n",
      "I0725 08:41:31.414727 140510523660096 basic_session_run_hooks.py:692] global_step/sec: 325.636\n",
      "I0725 08:41:31.415529 140510523660096 basic_session_run_hooks.py:260] average_loss = 0.5408014, loss = 21.632057 (0.307 sec)\n",
      "I0725 08:41:31.415841 140510523660096 basic_session_run_hooks.py:260] loss = 21.632057, step = 1001 (0.307 sec)\n",
      "I0725 08:41:31.724883 140510523660096 basic_session_run_hooks.py:692] global_step/sec: 322.397\n",
      "I0725 08:41:31.725644 140510523660096 basic_session_run_hooks.py:260] average_loss = 0.6176616, loss = 24.706463 (0.310 sec)\n",
      "I0725 08:41:31.725963 140510523660096 basic_session_run_hooks.py:260] loss = 24.706463, step = 1101 (0.310 sec)\n",
      "I0725 08:41:32.033095 140510523660096 basic_session_run_hooks.py:692] global_step/sec: 324.439\n",
      "I0725 08:41:32.033791 140510523660096 basic_session_run_hooks.py:260] average_loss = 0.29006177, loss = 11.60247 (0.308 sec)\n",
      "I0725 08:41:32.034080 140510523660096 basic_session_run_hooks.py:260] loss = 11.60247, step = 1201 (0.308 sec)\n",
      "I0725 08:41:32.343914 140510523660096 basic_session_run_hooks.py:692] global_step/sec: 321.769\n",
      "I0725 08:41:32.344836 140510523660096 basic_session_run_hooks.py:260] average_loss = 0.44728175, loss = 17.89127 (0.311 sec)\n",
      "I0725 08:41:32.345233 140510523660096 basic_session_run_hooks.py:260] loss = 17.89127, step = 1301 (0.311 sec)\n",
      "I0725 08:41:32.642200 140510523660096 basic_session_run_hooks.py:692] global_step/sec: 335.257\n",
      "I0725 08:41:32.643097 140510523660096 basic_session_run_hooks.py:260] average_loss = 0.39254433, loss = 15.701773 (0.298 sec)\n",
      "I0725 08:41:32.643292 140510523660096 basic_session_run_hooks.py:260] loss = 15.701773, step = 1401 (0.298 sec)\n",
      "I0725 08:41:32.953328 140510523660096 basic_session_run_hooks.py:692] global_step/sec: 321.347\n",
      "I0725 08:41:32.954031 140510523660096 basic_session_run_hooks.py:260] average_loss = 0.30464828, loss = 12.185931 (0.311 sec)\n",
      "I0725 08:41:32.954323 140510523660096 basic_session_run_hooks.py:260] loss = 12.185931, step = 1501 (0.311 sec)\n",
      "I0725 08:41:33.266640 140510523660096 basic_session_run_hooks.py:692] global_step/sec: 319.184\n",
      "I0725 08:41:33.267412 140510523660096 basic_session_run_hooks.py:260] average_loss = 0.20459528, loss = 8.183811 (0.313 sec)\n",
      "I0725 08:41:33.267706 140510523660096 basic_session_run_hooks.py:260] loss = 8.183811, step = 1601 (0.313 sec)\n",
      "I0725 08:41:33.367031 140510523660096 basic_session_run_hooks.py:606] Saving checkpoints for 1629 into /tmp/census_model/model.ckpt.\n",
      "I0725 08:41:33.525360 140510523660096 estimator.py:368] Loss for final step: 0.6106348.\n",
      "I0725 08:41:33.554269 140510523660096 census_dataset.py:167] Parsing /tmp/census_data/adult.test\n",
      "I0725 08:41:33.602458 140510523660096 estimator.py:1145] Calling model_fn.\n",
      "W0725 08:41:34.805365 140510523660096 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/metrics_impl.py:2027: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "W0725 08:41:35.285951 140510523660096 metrics_impl.py:804] Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "W0725 08:41:35.311571 140510523660096 metrics_impl.py:804] Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "I0725 08:41:35.338286 140510523660096 estimator.py:1147] Done calling model_fn.\n",
      "I0725 08:41:35.363411 140510523660096 evaluation.py:255] Starting evaluation at 2019-07-25T08:41:35Z\n",
      "I0725 08:41:35.603332 140510523660096 monitored_session.py:240] Graph was finalized.\n",
      "W0725 08:41:35.603858 140510523660096 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "I0725 08:41:35.605358 140510523660096 saver.py:1280] Restoring parameters from /tmp/census_model/model.ckpt-1629\n",
      "I0725 08:41:35.713743 140510523660096 session_manager.py:500] Running local_init_op.\n",
      "I0725 08:41:35.777275 140510523660096 session_manager.py:502] Done running local_init_op.\n",
      "I0725 08:41:37.171026 140510523660096 evaluation.py:275] Finished evaluation at 2019-07-25-08:41:37\n",
      "I0725 08:41:37.171309 140510523660096 estimator.py:2039] Saving dict for global step 1629: accuracy = 0.836128, accuracy_baseline = 0.76377374, auc = 0.8840271, auc_precision_recall = 0.69570607, average_loss = 0.3510044, global_step = 1629, label/mean = 0.23622628, loss = 14.006624, precision = 0.7026841, prediction/mean = 0.22982714, recall = 0.53094125\n",
      "I0725 08:41:37.456269 140510523660096 estimator.py:2099] Saving 'checkpoint_path' summary for global step 1629: /tmp/census_model/model.ckpt-1629\n",
      "I0725 08:41:37.457015 140510523660096 wide_deep_run_loop.py:116] Results at epoch 2 / 2\n",
      "I0725 08:41:37.457148 140510523660096 wide_deep_run_loop.py:117] ------------------------------------------------------------\n",
      "I0725 08:41:37.457253 140510523660096 wide_deep_run_loop.py:120] accuracy: 0.836128\n",
      "I0725 08:41:37.457329 140510523660096 wide_deep_run_loop.py:120] accuracy_baseline: 0.76377374\n",
      "I0725 08:41:37.457400 140510523660096 wide_deep_run_loop.py:120] auc: 0.8840271\n",
      "I0725 08:41:37.457469 140510523660096 wide_deep_run_loop.py:120] auc_precision_recall: 0.69570607\n",
      "I0725 08:41:37.457539 140510523660096 wide_deep_run_loop.py:120] average_loss: 0.3510044\n",
      "I0725 08:41:37.457630 140510523660096 wide_deep_run_loop.py:120] global_step: 1629\n",
      "I0725 08:41:37.457701 140510523660096 wide_deep_run_loop.py:120] label/mean: 0.23622628\n",
      "I0725 08:41:37.457772 140510523660096 wide_deep_run_loop.py:120] loss: 14.006624\n",
      "I0725 08:41:37.457842 140510523660096 wide_deep_run_loop.py:120] precision: 0.7026841\n",
      "I0725 08:41:37.457912 140510523660096 wide_deep_run_loop.py:120] prediction/mean: 0.22982714\n",
      "I0725 08:41:37.457999 140510523660096 wide_deep_run_loop.py:120] recall: 0.53094125\n",
      "I0725 08:41:37.458168 140510523660096 logger.py:147] Benchmark metric: {'name': 'accuracy', 'value': 0.8361279964447021, 'unit': None, 'global_step': 1629, 'timestamp': '2019-07-25T08:41:37.458119Z', 'extras': []}\n",
      "I0725 08:41:37.458317 140510523660096 logger.py:147] Benchmark metric: {'name': 'accuracy_baseline', 'value': 0.7637737393379211, 'unit': None, 'global_step': 1629, 'timestamp': '2019-07-25T08:41:37.458288Z', 'extras': []}\n",
      "I0725 08:41:37.458433 140510523660096 logger.py:147] Benchmark metric: {'name': 'auc', 'value': 0.8840271234512329, 'unit': None, 'global_step': 1629, 'timestamp': '2019-07-25T08:41:37.458406Z', 'extras': []}\n",
      "I0725 08:41:37.458575 140510523660096 logger.py:147] Benchmark metric: {'name': 'auc_precision_recall', 'value': 0.6957060694694519, 'unit': None, 'global_step': 1629, 'timestamp': '2019-07-25T08:41:37.458534Z', 'extras': []}\n",
      "I0725 08:41:37.458702 140510523660096 logger.py:147] Benchmark metric: {'name': 'average_loss', 'value': 0.35100439190864563, 'unit': None, 'global_step': 1629, 'timestamp': '2019-07-25T08:41:37.458660Z', 'extras': []}\n",
      "I0725 08:41:37.458821 140510523660096 logger.py:147] Benchmark metric: {'name': 'label/mean', 'value': 0.23622627556324005, 'unit': None, 'global_step': 1629, 'timestamp': '2019-07-25T08:41:37.458795Z', 'extras': []}\n",
      "I0725 08:41:37.458933 140510523660096 logger.py:147] Benchmark metric: {'name': 'loss', 'value': 14.006624221801758, 'unit': None, 'global_step': 1629, 'timestamp': '2019-07-25T08:41:37.458907Z', 'extras': []}\n",
      "I0725 08:41:37.459083 140510523660096 logger.py:147] Benchmark metric: {'name': 'precision', 'value': 0.7026841044425964, 'unit': None, 'global_step': 1629, 'timestamp': '2019-07-25T08:41:37.459055Z', 'extras': []}\n",
      "I0725 08:41:37.459200 140510523660096 logger.py:147] Benchmark metric: {'name': 'prediction/mean', 'value': 0.2298271358013153, 'unit': None, 'global_step': 1629, 'timestamp': '2019-07-25T08:41:37.459173Z', 'extras': []}\n",
      "I0725 08:41:37.459346 140510523660096 logger.py:147] Benchmark metric: {'name': 'recall', 'value': 0.5309412479400635, 'unit': None, 'global_step': 1629, 'timestamp': '2019-07-25T08:41:37.459321Z', 'extras': []}\n"
     ]
    }
   ],
   "source": [
    "!python -m official.wide_deep.census_main --model_type=wide --train_epochs=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adult.data  adult.test\r\n"
     ]
    }
   ],
   "source": [
    "!ls /tmp/census_data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = \"/tmp/census_data/adult.data\"\n",
    "test_file = \"/tmp/census_data/adult.test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "32561\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'?',\n",
       " 'Adm-clerical',\n",
       " 'Armed-Forces',\n",
       " 'Craft-repair',\n",
       " 'Exec-managerial',\n",
       " 'Farming-fishing',\n",
       " 'Handlers-cleaners',\n",
       " 'Machine-op-inspct',\n",
       " 'Other-service',\n",
       " 'Priv-house-serv',\n",
       " 'Prof-specialty',\n",
       " 'Protective-serv',\n",
       " 'Sales',\n",
       " 'Tech-support',\n",
       " 'Transport-moving'}"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas\n",
    "\n",
    "train_df = pandas.read_csv(train_file, header=None, names=census_dataset._CSV_COLUMNS)\n",
    "test_df = pandas.read_csv(test_file, header=None, names=census_dataset._CSV_COLUMNS)\n",
    "census_dataset._CSV_COLUMNS\n",
    "\n",
    "print(train_df.columns.size)\n",
    "print(train_df.index.size)\n",
    "train_df.head()\n",
    "set(train_df['occupation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def easy_input_function(df, label_key, num_epochs, shuffle, batch_size):\n",
    "    label = df[label_key]\n",
    "    ds = tf.data.Dataset.from_tensor_slices((dict(df),label))\n",
    "    \n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(10000)\n",
    "    ds = ds.batch(batch_size).repeat(num_epochs)\n",
    "    \n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "some feature keys: ['age', 'workclass', 'fnlwgt', 'education', 'education_num', 'marital_status', 'occupation', 'relationship', 'race', 'gender', 'capital_gain', 'capital_loss', 'hours_per_week', 'native_country', 'income_bracket']\n",
      "\n",
      "A batch of Age: tf.Tensor([57 23 51 44 29 49 24 24 24 34], shape=(10,), dtype=int32)\n",
      "\n",
      "A batch of Label: tf.Tensor(\n",
      "[b'<=50K' b'<=50K' b'<=50K' b'<=50K' b'<=50K' b'>50K' b'<=50K' b'<=50K'\n",
      " b'<=50K' b'>50K'], shape=(10,), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "ds = easy_input_function(train_df, label_key='income_bracket',\n",
    "                        num_epochs=5,shuffle=True, batch_size=10)\n",
    "\n",
    "for feature_batch,label_batch in ds.take(1):\n",
    "    print('some feature keys:', list(feature_batch.keys()))\n",
    "    print()\n",
    "    print('A batch of Age:', feature_batch['age'])\n",
    "    print()\n",
    "    print('A batch of Label:', label_batch)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def input_fn(data_file, num_epochs, shuffle, batch_size):\n",
      "  \"\"\"Generate an input function for the Estimator.\"\"\"\n",
      "  assert tf.gfile.Exists(data_file), (\n",
      "      '%s not found. Please make sure you have run census_dataset.py and '\n",
      "      'set the --data_dir argument to the correct path.' % data_file)\n",
      "\n",
      "  def parse_csv(value):\n",
      "    tf.logging.info('Parsing {}'.format(data_file))\n",
      "    columns = tf.decode_csv(value, record_defaults=_CSV_COLUMN_DEFAULTS)\n",
      "    features = dict(zip(_CSV_COLUMNS, columns))\n",
      "    labels = features.pop('income_bracket')\n",
      "    classes = tf.equal(labels, '>50K')  # binary classification\n",
      "    return features, classes\n",
      "\n",
      "  # Extract lines from input files using the Dataset API.\n",
      "  dataset = tf.data.TextLineDataset(data_file)\n",
      "\n",
      "  if shuffle:\n",
      "    dataset = dataset.shuffle(buffer_size=_NUM_EXAMPLES['train'])\n",
      "\n",
      "  dataset = dataset.map(parse_csv, num_parallel_calls=5)\n",
      "\n",
      "  # We call repeat after shuffling, rather than before, to prevent separate\n",
      "  # epochs from blending together.\n",
      "  dataset = dataset.repeat(num_epochs)\n",
      "  dataset = dataset.batch(batch_size)\n",
      "  return dataset\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import inspect\n",
    "print(inspect.getsource(census_dataset.input_fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature keys: ['age', 'workclass', 'fnlwgt', 'education', 'education_num']\n",
      "\n",
      "Age batch: tf.Tensor([67 18 30 35 20 42 38 48 29 49], shape=(10,), dtype=int32)\n",
      "\n",
      "Label batch: tf.Tensor([False False False False False False  True False False False], shape=(10,), dtype=bool)\n"
     ]
    }
   ],
   "source": [
    "ds = census_dataset.input_fn(train_file, num_epochs=5, shuffle=True, batch_size=10)\n",
    "\n",
    "for feature_batch, label_batch in ds.take(1):\n",
    "    print('Feature keys:', list(feature_batch.keys())[:5])\n",
    "    print()\n",
    "    print('Age batch:', feature_batch['age'])\n",
    "    print()\n",
    "    print('Label batch:', label_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function official.wide_deep.census_dataset.input_fn(data_file, num_epochs, shuffle, batch_size)>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import functools\n",
    "\n",
    "train_inpf = functools.partial(census_dataset.input_fn, train_file,\n",
    "                              num_epochs=2, shuffle=True, batch_size=64)\n",
    "test_inpf = functools.partial(census_dataset.input_fn, test_file,\n",
    "                              num_epochs=1, shuffle=True, batch_size=64)\n",
    "train_inpf\n",
    "census_dataset.input_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NumericColumn(key='age', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "age = fc.numeric_column('age')\n",
    "age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0726 03:07:16.695712 140427323885376 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/feature_column/feature_column.py:205: NumericColumn._get_dense_tensor (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
      "W0726 03:07:16.697372 140427323885376 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/feature_column/feature_column.py:2115: NumericColumn._transform_feature (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
      "W0726 03:07:16.699953 140427323885376 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/feature_column/feature_column.py:206: NumericColumn._variable_shape (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[67.],\n",
       "       [18.],\n",
       "       [30.],\n",
       "       [35.],\n",
       "       [20.],\n",
       "       [42.],\n",
       "       [38.],\n",
       "       [48.],\n",
       "       [29.],\n",
       "       [49.]], dtype=float32)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc.input_layer(feature_batch,[age]).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.76377374, 'accuracy_baseline': 0.76377374, 'auc': 0.6780343, 'auc_precision_recall': 0.3112702, 'average_loss': 0.5260417, 'label/mean': 0.23622628, 'loss': 33.586212, 'precision': 0.0, 'prediction/mean': 0.21324953, 'recall': 0.0, 'global_step': 1018}\n"
     ]
    }
   ],
   "source": [
    "classifier = tf.estimator.LinearClassifier(feature_columns=[age])\n",
    "classifier.train(train_inpf)\n",
    "result= classifier.evaluate(test_inpf)\n",
    "clear_output()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.700e+01, 0.000e+00, 0.000e+00, 1.000e+01, 4.000e+01],\n",
       "       [1.800e+01, 0.000e+00, 0.000e+00, 6.000e+00, 2.500e+01],\n",
       "       [3.000e+01, 0.000e+00, 0.000e+00, 9.000e+00, 4.000e+01],\n",
       "       [3.500e+01, 0.000e+00, 0.000e+00, 1.000e+01, 3.500e+01],\n",
       "       [2.000e+01, 0.000e+00, 0.000e+00, 1.000e+01, 1.500e+01],\n",
       "       [4.200e+01, 0.000e+00, 0.000e+00, 1.400e+01, 3.800e+01],\n",
       "       [3.800e+01, 7.688e+03, 0.000e+00, 1.600e+01, 4.000e+01],\n",
       "       [4.800e+01, 0.000e+00, 0.000e+00, 1.000e+01, 4.400e+01],\n",
       "       [2.900e+01, 0.000e+00, 0.000e+00, 1.500e+01, 5.500e+01],\n",
       "       [4.900e+01, 0.000e+00, 0.000e+00, 9.000e+00, 4.000e+01]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "education_num = tf.feature_column.numeric_column('education_num')\n",
    "capital_gain = tf.feature_column.numeric_column('capital_gain')\n",
    "capital_loss= tf.feature_column.numeric_column('capital_loss')\n",
    "hours_per_week= tf.feature_column.numeric_column('hours_per_week')\n",
    "\n",
    "my_numeric_columns = [age, education_num, capital_gain, \\\n",
    "                      capital_loss, hours_per_week]\n",
    "\n",
    "fc.input_layer(feature_batch,my_numeric_columns).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0726 03:41:49.784833 140427323885376 estimator.py:1811] Using temporary folder as model directory: /tmp/tmp2yn3zoia\n",
      "W0726 03:41:56.426391 140427323885376 metrics_impl.py:804] Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "W0726 03:41:56.454896 140427323885376 metrics_impl.py:804] Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:0.7826301\n",
      "accuracy_baseline:0.76377374\n",
      "auc:0.71703655\n",
      "auc_precision_recall:0.51337904\n",
      "average_loss:1.2810885\n",
      "global_step:1018\n",
      "label/mean:0.23622628\n",
      "loss:81.79373\n",
      "precision:0.61619985\n",
      "prediction/mean:0.24470079\n",
      "recall:0.21164846\n"
     ]
    }
   ],
   "source": [
    "classifier = tf.estimator.LinearClassifier(feature_columns=my_numeric_columns)\n",
    "classifier.train(train_inpf)\n",
    "\n",
    "result = classifier.evaluate(test_inpf)\n",
    "\n",
    "for key, value in sorted(result.items()):\n",
    "    print('%s:%s'% (key,value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VocabularyListCategoricalColumn(key='relationship', vocabulary_list=('Husband', 'Not-in-family', 'Other-relative', 'Own-child', 'Unmarried', 'Wife'), dtype=tf.string, default_value=-1, num_oov_buckets=0)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "relationship = fc.categorical_column_with_vocabulary_list(\n",
    "    'relationship',\n",
    "    ['Husband',\n",
    "     'Not-in-family',\n",
    "     'Other-relative',\n",
    "     'Own-child',\n",
    "     'Unmarried',\n",
    "     'Wife'])\n",
    "relationship \n",
    "#fc.indicator_column(relationship)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0726 08:46:51.401709 140427323885376 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/feature_column/feature_column.py:205: IndicatorColumn._get_dense_tensor (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
      "W0726 08:46:51.403178 140427323885376 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/feature_column/feature_column.py:2115: IndicatorColumn._transform_feature (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
      "W0726 08:46:51.404257 140427323885376 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/feature_column/feature_column_v2.py:4236: VocabularyListCategoricalColumn._get_sparse_tensors (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
      "W0726 08:46:51.405285 140427323885376 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/feature_column/feature_column.py:2115: VocabularyListCategoricalColumn._transform_feature (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
      "W0726 08:46:51.410784 140427323885376 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/feature_column/feature_column_v2.py:4207: IndicatorColumn._variable_shape (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
      "W0726 08:46:51.411798 140427323885376 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/feature_column/feature_column_v2.py:4262: VocabularyListCategoricalColumn._num_buckets (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=12524, shape=(10, 7), dtype=float32, numpy=\n",
       "array([[67.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [18.,  0.,  0.,  0.,  1.,  0.,  0.],\n",
       "       [30.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [35.,  0.,  1.,  0.,  0.,  0.,  0.],\n",
       "       [20.,  0.,  0.,  0.,  1.,  0.,  0.],\n",
       "       [42.,  0.,  1.,  0.,  0.,  0.,  0.],\n",
       "       [38.,  0.,  0.,  0.,  0.,  0.,  1.],\n",
       "       [48.,  0.,  0.,  0.,  0.,  1.,  0.],\n",
       "       [29.,  0.,  1.,  0.,  0.,  0.,  0.],\n",
       "       [49.,  1.,  0.,  0.,  0.,  0.,  0.]], dtype=float32)>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc.input_layer(feature_batch, [age, fc.indicator_column(relationship)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "occupation = tf.feature_column.categorical_column_with_hash_bucket(\n",
    "    'occupation',hash_bucket_size=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
